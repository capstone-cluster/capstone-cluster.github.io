<!DOCTYPE html>
<html lang="en">
  <head id="head">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width" />
    <meta name="description" content="Project CLUSTER - Multi-Purpose HPC Computing for the ECE Department">
    <meta name="author" content="Project CLUSTER">
    <title>Project CLUSTER</title>
    <link rel="shortcut icon" href="img/favicon.ico">
    <!-- CSS/JS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css">
    <script src="https://cdn.jsdelivr.net/combine/npm/jquery@3.4.1/dist/jquery.min.js,npm/bootstrap@4.3.1/dist/js/bootstrap.min.js"></script>
    <link href="css/style.css" rel="stylesheet" type="text/css">
  </head>

  <body class="bg-dark" data-spy="scroll" data-target=".navbar" data-offset="75">
    <header>
      <nav class="navbar fixed-top nav-pills navbar-expand-lg navbar-dark bg-dark">
        <a class="navbar-brand" href="/index.html#head"><i class="fa fa-server"></i> Project CLUSTER</a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarSupportedContent">
          <div class="navbar-nav ml-auto">
            <a class="nav-item nav-link" href="/index.html#about">About</a>
            <a class="nav-item nav-link" href="/index.html#team">Team</a>
            <a class="nav-item nav-link" href="/index.html#contact">Contact</a>
          </div>
        </div>
      </nav>
    </header>
    <main role="main">
      <section class="jumbotron text-center" id="blog-top">
        <div class="container-fluid">
          <h1 class="jumbotron-heading">Adam's Blog</h1>
          <hr />
          <p>
            A journal of everything I've done for Project CLUSTER
          </p>
        </div>
      </section>
      <section id="blog-section">
        <br><br>
        <div class="container-fluid">
          <div class="row justify-content-center">
            <div class="col-10 col-md-8">
              <div class="blog-post">
                <h2 class="blog-post-title">Week of May 11th</h2>
                <p class="blog-post-meta">May 15, 2020 by Adam Dadey</p>
                <p>
                  This is my final update.  We had our final presentation on May 12.
                  It went great!  The remainder of the time will be spent working on the
                  final report and compiling all software and documentation due on May 20.
                  That's all for me.  Adam signing off!
                </p>
              </div>
            </div>
          </div>
        </div>
        <div class="container-fluid">
          <div class="row justify-content-center">
            <div class="col-10 col-md-8">
              <div class="blog-post">
                <h2 class="blog-post-title">Week of May 4th</h2>
                <p class="blog-post-meta">May 7, 2020 by Adam Dadey</p>
                <p>
                  This week I started preparing for our final presentation on May 12th
                  at 5pm.  I plan on doing a live demo showing off slurm on the C7000.
                  Just in case the live demo doesn't go as planned, I recorded a demo
                  video that I can play.  For the remainder of the week leading up to
                  the presentation I will be updating the slides and preparing what I
                  want to say.
                </p>
              </div>
            </div>
          </div>
        </div>
        <div class="container-fluid">
          <div class="row justify-content-center">
            <div class="col-10 col-md-8">
              <div class="blog-post">
                <h2 class="blog-post-title">Week of April 27th</h2>
                <p class="blog-post-meta">April 30, 2020 by Adam Dadey</p>
                <p>
                  This week I was able to implement a four node slurm cluster on a C7000.
                  There is one master node and three workers each with 32 cores and 8 GB
                  of memory. Working with Dr. Cotton, I was able to get one of the network
                  switches in the C7000 disconnected from the UD Network.  I used this switch
                  as the LAN for pfSense.  In this implementatation, the slurm master and pfSense
                  are running in VMs on ESXi on one of the blades.  The three workers are each
                  running on their own blade. All nodes of the cluster are able to connect to the
                  pfSense LAN network and communicate with eachother.
                </p>
                <p>
                  I ran the prime.mpi script I was previosuly using th benchmark the scaling
                  performance of the slurm cluster.  I've attached an image below showing the
                  performance for one, two, and three nodes, equivalent to 32, 64, and 96 cores!
                  It's interesting to note that the jump from 64 to 96 cores didn't result in a
                  significant performance increase.
                </p>
                <a href="/img/blog-adam/C7000_scaling_results.png" data-lightbox="image">
                  <div class="justify-content-center d-flex">
                    <img class="img-fluid" src="/img/blog-adam/C7000_scaling_results.png" style="max-width: 100%; align-self: center; border: 2px solid #000;">
                  </div>
                </a>
              </div>
            </div>
          </div>
        </div>
        <div class="container-fluid">
          <div class="row justify-content-center">
            <div class="col-10 col-md-8">
              <div class="blog-post">
                <h2 class="blog-post-title">Week of April 20th</h2>
                <p class="blog-post-meta">April 23, 2020 by Adam Dadey</p>
                <p>
                  This week Dr. Cotton got the C7000 up and running and we now access. There is
                  still one change that needs to be made, namely, one of the physical switches
                  of the C7000 needs to be taken off the interent so it can be used as a pfSense
                  LAN.  Once that is complete I can start implementing slurm on the C7000!
                </p>
                <p>
                  Additionally, I created a pfSense VM and configured it as I would
                  on the C7000.  All of the nodes of the slurm cluster were successfully
                  moved under pfSense and cluster is still functioning.  Also, I found
                  that in the pfSense console you can temporarily disable packet filtering
                  to gain access to the webGUI through the WAN interface of pfSense. This
                  means there is no need to a VPN into the LAN side of pfSense in order to
                  adjust the configuration.  Additonally, a firewall rule can be created to
                  enable webGUI access of the WAN.  Below are two pictures that show how to
                  gain access to the webGUI over the WAN.
                </p>
                <a href="/img/blog-adam/pfSense-disable-packetfilter.png" data-lightbox="image">
                  <div class="justify-content-center d-flex">
                    <img class="img-fluid" src="/img/blog-adam/pfSense-disable-packetfilter.png" style="max-width: 70%; align-self: center; border: 2px solid #000;">
                  </div>
                </a>
                <p></p>
                <a href="/img/blog-adam/pfSense_webgui_over_WAN.PNG" data-lightbox="image">
                  <div class="justify-content-center d-flex">
                    <img class="img-fluid" src="/img/blog-adam/pfSense_webgui_over_WAN.PNG" style="max-width: 70%; align-self: center; border: 2px solid #000;">
                  </div>
                </a>
              </div>
            </div>
          </div>
        </div>
        <div class="container-fluid">
          <div class="row justify-content-center">
            <div class="col-10 col-md-8">
              <div class="blog-post">
                <h2 class="blog-post-title">Week of April 13th</h2>
                <p class="blog-post-meta">April 16, 2020 by Adam Dadey</p>
                <p>
                  This week we got the R805 setup off campus.  Now, we can connect
                  to the server without having to VPN into the UD Network.  I'm still
                  waiting on the C7000 to be up... Dr. Cottton said he was putting
                  together a Zoom recording on how to access the server.  Hopefully I
                  can start implementing slurm on the C7000 next week.
                </p>
              </div>
            </div>
          </div>
        </div>
        <div class="container-fluid">
          <div class="row justify-content-center">
            <div class="col-10 col-md-8">
              <div class="blog-post">
                <h2 class="blog-post-title">Week of April 6th</h2>
                <p class="blog-post-meta">April 9, 2020 by Adam Dadey</p>
                <p>
                  Due to COVID-19, Spring Break was moved up to the week of March 16th
                  and extended through the week of March 23rd.  Not much progress was
                  made during the week of March 30th.  We mainly had meetings discussing
                  how the project would continue.  This week I made two "installers", one
                  for configuring a master node and the other for configuring a worker node.
                  Now, all one has to do to configure a node is copy over the respective archive
                  to a node with CentOS 7 installed and run the configure script. These
                  scripts are ready to go when we get the C7000.  Cotton is close to having
                  them ready.  Hopefully I can start implementing slurm on a C7000
                  next week! Fingers crossed...
                </p>
                <p>
                  For fun, I used the configure script to create a fourth worker node. After
                  running the configure script the node was ready to go and automatically
                  became allocatable on the slurm cluster!  I ran the prime.mpi script
                  including the new node and was able to finish the calculation is a quarter
                  of the time compared to three nodes!  Below is an image of the results.
                </p>
                <a href="/img/blog-adam/slurm-prime-mpi-4-node-results.png" data-lightbox="image">
                  <div class="justify-content-center d-flex">
                    <img class="img-fluid" src="/img/blog-adam/slurm-prime-mpi-4-node-results.png" style="max-width: 45%; align-self: center; border: 2px solid #000;">
                  </div>
                </a>
              </div>
            </div>
          </div>
        </div>
        <div class="container-fluid">
          <div class="row justify-content-center">
            <div class="col-10 col-md-8">
              <div class="blog-post">
                <h2 class="blog-post-title">Week of March 9th</h2>
                <p class="blog-post-meta">March 12, 2020 by Adam Dadey</p>
                <p>
                  This week I worked out some bugs with the cluster configuration
                  script I started drafting a few weeks ago.  The script now correctly
                  downloads, installs, and configures MUNGE, slurm, and Open MPI.  Dr.
                  Cotton is making progress with getting the C7000s up.  When the blades
                  are up I will be ready to start implementing the supercomputer on the
                  blades.  Additonally, all classes are supposed to be online due to
                  Coronavirus fears.  Hopefully this does not impede the progress of
                  this project.
                </p>
              </div>
            </div>
          </div>
        </div>
        <div class="container-fluid">
          <div class="row justify-content-center">
            <div class="col-10 col-md-8">
              <div class="blog-post">
                <h2 class="blog-post-title">Week of March 2nd</h2>
                <p class="blog-post-meta">March 5, 2020 by Adam Dadey</p>
                <p>
                  This week I was visiting UT Austin as a potential graduate school
                  on Thursday and Friday so I did not do any work on the project.
                  Dr. Cotton started fixing up the C7000 though, so I will hopefully
                  be able to start moving slurm to an actual cluster next week.
                </p>
              </div>
            </div>
          </div>
        </div>
        <div class="container-fluid">
          <div class="row justify-content-center">
            <div class="col-10 col-md-8">
              <div class="blog-post">
                <h2 class="blog-post-title">Week of February 24th</h2>
                <p class="blog-post-meta">February 27, 2020 by Adam Dadey</p>
                <p>
                  This week I drafted a configuration script that will install and
                  configure all required software for each node on the cluster.  In
                  its current state, the admin will still have to do a few extra steps
                  after running the script to fully configure a node.  I plan to make
                  the script do all the configuration in the future.  Additionally, I
                  ran a prime number finding mpi program in the cluster and compared
                  calculation times for one node and three nodes.  Not suprisingly,
                  three nodes were able to finish the calculation quicker than one node.
                  The results for one node and three nodes are below on the left and
                  right respectively.
                </p>
                <a href="/img/blog-adam/slurm-prime-mpi-results.png" data-lightbox="image">
                  <div class="justify-content-center d-flex">
                    <img class="img-fluid" src="/img/blog-adam/slurm-prime-mpi-results.png" style="max-width: 70%; align-self: center; border: 2px solid #000;">
                  </div>
                </a>
              </div>
            </div>
          </div>
        </div>
        <div class="container-fluid">
          <div class="row justify-content-center">
            <div class="col-10 col-md-8">
              <div class="blog-post">
                <h2 class="blog-post-title">Week of February 17th</h2>
                <p class="blog-post-meta">February 20, 2020 by Adam Dadey</p>
                <p>
                  This week I got the sbcast command to work with slurm.  The sbcast
                  command is supposed to be used to disperse a file to all the nodes
                  allocated to a specific job.  Unfortunately, the command was throwing
                  an error saying it could not find the given file.  The problem was that
                  the sbcast command was being run on the first node allocated to the job.
                  I initialized the job on the master, so the sbcast command was being run
                  on the first worker.  The file I was trying to disperse was not on the
                  worker node so it was throwing an error.  The solution is to run jobs from
                  the worker.  With this change the command worked!
                </p>
                <a href="/img/blog-adam/slurm-sbcast-script.png" data-lightbox="image">
                  <div class="justify-content-center d-flex">
                    <img class="img-fluid" src="/img/blog-adam/slurm-sbcast-script.png" style="max-width: 65%; align-self: center; border: 2px solid #000;">
                  </div>
                </a>
              </div>
            </div>
          </div>
        </div>
        <div class="container-fluid">
          <div class="row justify-content-center">
            <div class="col-10 col-md-8">
              <div class="blog-post">
                <h2 class="blog-post-title">Week of February 10th</h2>
                <p class="blog-post-meta">February 13, 2020 by Adam Dadey</p>
                <p>
                  This week was the first week of Spring Semester. I installed Open MPI,
                  which allows for parallel processing in the cluster. Additionally,
                  I adjusted the slurm.conf file so that system memory is an allocatable
                  resource. I researched OpenHPC, a set of tools for creating a cluster. One
                  of the guides describes using CentOS 7 as the base os, Warewulf to install
                  and manage the cluster, and slurm as the job scheduler for the cluster. This
                  configuration is very similar to what I currently have implemented on VMs.
                  I could potentially use the OpenHPC resources for implementing the cluster
                  on the C7000 blades. Finally, I've been reading up on slurm documentation
                  to get a better grasp of its functionality. Below is a image of a submit
                  script that demonstrates memory allocation and running an MPI program.
                </p>
                <a href="/img/blog-adam/slurm-sbatch-script-mpi.png" data-lightbox="image">
                  <div class="justify-content-center d-flex">
                    <img class="img-fluid" src="/img/blog-adam/slurm-sbatch-script-mpi.png" style="max-width: 65%; align-self: center; border: 2px solid #000;">
                  </div>
                </a>
              </div>
            </div>
          </div>
        </div>
        <div class="container-fluid">
          <div class="row justify-content-center">
            <div class="col-10 col-md-8">
              <div class="blog-post">
                <h2 class="blog-post-title">Week of November 25th (Thanksgiving Break)</h2>
                <p class="blog-post-meta">November 30, 2019 by Adam Dadey</p>
                <p>
                  This week I worked on the Mid-Year Presentation. Our presentation is either
                  December 3rd or 5th so I wanted to get a head start on formatting and
                  filling in the presentation.
                </p>
              </div>
            </div>
          </div>
        </div>
        <div class="container-fluid">
          <div class="row justify-content-center">
            <div class="col-10 col-md-8">
              <div class="blog-post">
                <h2 class="blog-post-title">Week of November 19th</h2>
                <p class="blog-post-meta">November 21, 2019 by Adam Dadey</p>
                <p>
                  This week I worked out some bugs with slurm.  I found that over time
                  the clocks across the cluster would become out of sync.  The MUNGE
                  authenticator needs in sync clocks.  I created bash script to run on
                  each node that syncs the node with an NTP server.  Additionally, I set up
                  logging for running and completed jobs.  Below is a screenshot of the
                  completed jobs log filled with a few completed jobs.
                </p>
                <a href="/img/blog-adam/slurm-master-job-log.png" data-lightbox="image">
                  <div class="justify-content-center d-flex">
                    <img class="img-fluid" src="/img/blog-adam/slurm-master-job-log.png" style="max-width: 65%; align-self: center; border: 2px solid #000;">
                  </div>
                </a>
              </div>
            </div>
          </div>
        </div>
        <div class="container-fluid">
          <div class="row justify-content-center">
            <div class="col-10 col-md-8">
              <div class="blog-post">
                <h2 class="blog-post-title">Week of November 11th</h2>
                <p class="blog-post-meta">November 14, 2019 by Adam Dadey</p>
                <p>
                  This week I was able to create a head node and worker node and get them to
                  communicated with eachother.  Unfortunately, while trying to install slurm
                  I encountered an error during the source build because it could not find python.
                  In CentOS 8, the version I was using, there is no default python environment, which
                  the builder relies on.  To fix this problem I moved to CentOS 7 and was successfully
                  able to build and install slurm on both the head node and worker node.  Below is an
                  image of the 'scontrol show nodes' command which properly shows the worker node.
                </p>
                <a href="/img/blog-adam/slurm-master-found-node.png" data-lightbox="image">
                  <div class="justify-content-center d-flex">
                    <img class="img-fluid" src="/img/blog-adam/slurm-master-found-node.png" style="max-width: 65%; align-self: center; border: 2px solid #000;">
                  </div>
                </a>
              </div>
            </div>
          </div>
        </div>
        <div class="container-fluid">
          <div class="row justify-content-center">
            <div class="col-10 col-md-8">
              <div class="blog-post">
                <h2 class="blog-post-title">Week of November 4th</h2>
                <p class="blog-post-meta">November 7, 2019 by Adam Dadey</p>
                <p>
                  This week I started exploring slurm, an open source job scheduler commonly used
                  in supercomputers.  We plan to use slurm as the backbone of our cluster supercomputer.
                  Red Hat is a common linux distro for cluster nodes, so I am experimenting with CentOS, a
                  free version of Red Hat, as the barebones OS for each node on the cluster.  In VMWare, I
                  started configuring a test master and worker node by first installing MUNGE.  MUNGE is an
                  authentication service used to create and validate credentials, and it is used by slurm.
                </p>
                <a href="/img/blog-adam/centos.png" data-lightbox="image">
                  <div class="justify-content-center d-flex">
                    <img class="img-fluid" src="/img/blog-adam/centos.png" style="max-width: 65%; align-self: center; border: 2px solid #000;">
                  </div>
                </a>
              </div>
            </div>
          </div>
        </div>
        <div class="container-fluid">
          <div class="row justify-content-center">
            <div class="col-10 col-md-8">
              <div class="blog-post">
                <h2 class="blog-post-title">Week of October 28th</h2>
                <p class="blog-post-meta">October 31, 2019 by Adam Dadey</p>
                <p>
                  This week I got an email from UD IT about a vulnerability,
                  CVE-2019-5119, in our server. This vulnerability deals with
                  the version of ESXi we are running.  The solution was the update
                  ESXi to the latest patch.  I was able to SSH into the server,
                  patch the software, and remove the vulnerability.  Below is a
                  description of the CVE.
                </p>
                <a href="/img/blog-adam/ESXi_CVE.png" data-lightbox="image">
                  <div class="justify-content-center d-flex">
                    <img class="img-fluid" src="/img/blog-adam/ESXi_CVE.png" style="max-width: 85%; align-self: center; border: 2px solid #000;">
                  </div>
                </a>
              </div>
            </div>
          </div>
        </div>
        <div class="container-fluid">
          <div class="row justify-content-center">
            <div class="col-10 col-md-8">
              <div class="blog-post">
                <h2 class="blog-post-title">Week of October 21st</h2>
                <p class="blog-post-meta">October 25, 2019 by Adam Dadey</p>
                <p>
                  This week I tried to solve the problem with Alpine Linux from
                  last week.  This effort was unsuccessful.  Although, we found
                  that Rancher orchestration uses RancherOS as the base OS and
                  we had success spawning nodes.  We have decided to no longer
                  pursue Alpine Linux as a base OS for each node of the cluster.
                </p>
              </div>
            </div>
          </div>
        </div>
        <div class="container-fluid">
          <div class="row justify-content-center">
            <div class="col-10 col-md-8">
              <div class="blog-post">
                <h2 class="blog-post-title">Week of October 14th</h2>
                <p class="blog-post-meta">October 18, 2019 by Adam Dadey</p>
                <p>
                  This week I experimented with light weight linux distros to use as a baremetal
                  operating system for each worker computer in the cluster.  I found that Alpine
                  Linux is a popular light weight distro for cluster computing.  I was able to
                  successfully install the OS on ESXi and install Docker.  Although, there is
                  currently a problem getting the worker to communicate with the cluster.  I hope
                  to fix this problem next week.  Below is an image of Alpine running in ESXi.
                </p>
                <a href="/img/blog-adam/alpine_splash.PNG" data-lightbox="image">
                  <div class="justify-content-center d-flex">
                    <img class="img-fluid" src="/img/blog-adam/alpine_splash.PNG" style="max-width: 60%; align-self: center; border: 2px solid #000;">
                  </div>
                </a>
              </div>
            </div>
          </div>
        </div>
        <div class="container-fluid">
          <div class="row justify-content-center">
            <div class="col-10 col-md-8">
              <div class="blog-post">
                <h2 class="blog-post-title">Week of October 7th</h2>
                <p class="blog-post-meta">October 11, 2019 by Adam Dadey</p>
                <p>
                  This week I setup the DRAC5 on the Dell R805 server.  I found that Internet Explorer
                  is required to use the server console view and insert virtual media.  Although,
                  browsers like Firefox or Chrome can be used to view the web based splash screen for
                  the server. Below is an image of the DRAC5 main screen.
                </p>
                <a href="/img/blog-adam/DRAC_splash_screen.PNG" data-lightbox="image">
                  <div class="justify-content-center d-flex">
                    <img class="img-fluid" src="/img/blog-adam/DRAC_splash_screen.PNG" style="max-width: 85%; align-self: center; border: 2px solid #000;">
                  </div>
                </a>
              </div>
            </div>
          </div>
        </div>
        <div class="container-fluid">
          <div class="row justify-content-center">
            <div class="col-10 col-md-8">
              <div class="blog-post">
                <h2 class="blog-post-title">Week of September 30th</h2>
                <p class="blog-post-meta">October 4, 2019 by Adam Dadey</p>
                <p>
                  This week I installed and configured RancherOS in VMWare Workstation.  We plan to
                  use Rancher to manage our Kubernetes cluster.  RancherOS is a containerized version
                  of Linux designed to be a lightweight baremetal OS for Rancher. I was able to create
                  and link three RancherOS VMs, one for the main controller and two as workers.  The
                  three VMs were able to successfully work with eachother.  Below is an image of
                  RancherOS running in a VM.
                </p>
                <a href="/img/blog-adam/RancherOS_splash.png" data-lightbox="image">
                  <div class="justify-content-center d-flex">
                    <img class="img-fluid" src="/img/blog-adam/RancherOS_splash.png" style="max-width: 85%; align-self: center; border: 2px solid #000;">
                  </div>
                </a>
              </div>
            </div>
          </div>
        </div>
      </section>
    </main>
    <footer>
      <p class="text-center">
        Copyright &copy;
        <script type="text/JavaScript">document.write(new Date().getFullYear());</script>
        Project CLUSTER, All Rights Reserved
      </p>
    </footer>
    <!-- CSS/JS -->
    <link href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css" rel="stylesheet" type="text/css" media="none" onload="if(media!='all')media='all'"><noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css"></noscript>
    <script src="js/main.js"></script>
    <link href="https://cdn.jsdelivr.net/npm/lightbox2@2.11.1/dist/css/lightbox.min.css" rel="stylesheet" type="text/css">
    <script src="https://cdn.jsdelivr.net/npm/lightbox2@2.11.1/dist/js/lightbox.min.js"></script>
  </body>

</html>
